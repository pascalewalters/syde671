{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SYDE 671 Assignment 4 Part 2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb2iyiFI7w7m",
        "colab_type": "code",
        "outputId": "1f62fad6-7607-4e0c-bc30-c821a797d633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe0Z_2pA8Ei3",
        "colab_type": "code",
        "outputId": "c91e282d-71e4-4e43-c476-1a8eb09a55bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# !pip install numpy==1.16.1\n",
        "# !pip install tensorpack\n",
        "\n",
        "!pip install numpy==1.15.4\n",
        "!pip install tensorpack==0.9.8\n",
        "!pip install tensorflow==1.14\n",
        "!pip install tensorflow-gpu==1.14\n",
        "!pip install gast==0.2.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 2.8MB/s \n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.17.3\n",
            "    Uninstalling numpy-1.17.3:\n",
            "      Successfully uninstalled numpy-1.17.3\n",
            "Successfully installed numpy-1.15.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorpack==0.9.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cb/62dc9115722a0b4fbeca6275ffbe47118149171ffafa7d1db6e295453aae/tensorpack-0.9.8-py2.py3-none-any.whl (288kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 2.8MB/s \n",
            "\u001b[?25hCollecting tqdm>4.29.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/08/8505f192efc72bfafec79655e1d8351d219e2b80b0dec4ae71f50934c17a/tqdm-4.38.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (0.5.6)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (0.8.5)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (1.15.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (5.4.8)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (17.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8) (1.12.0)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/ab/09904a909bccc471f219fb8f5d0838cbcb10cc26089a2b29e84c893e216e/msgpack_numpy-0.4.4.3-py2.py3-none-any.whl\n",
            "Installing collected packages: tqdm, msgpack-numpy, tensorpack\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed msgpack-numpy-0.4.4.3 tensorpack-0.9.8 tqdm-4.38.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 69kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (41.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.15.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (0.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xyG7ENK8jWc",
        "colab_type": "code",
        "outputId": "af86e3c6-3228-49ff-cf5e-4de197ce50f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "from glob import glob\n",
        "\n",
        "from tensorpack import *\n",
        "from tensorpack.tfutils.sessinit import get_model_loader\n",
        "from tensorpack.tfutils.symbolic_functions import *\n",
        "from tensorpack.tfutils.summary import *\n",
        "from tensorpack.utils.gpu import get_nr_gpu\n",
        "from tensorpack.dataflow.base import RNGDataFlow\n",
        "from tensorpack.tfutils.tower import get_current_tower_context\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndqi80Qy89Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Scene15(RNGDataFlow):\n",
        "\n",
        "    def __init__(self, dir, name, img_size, meta_dir=None,\n",
        "                 shuffle=None, dir_structure=None):\n",
        "\n",
        "        assert name in ['train', 'test'], name\n",
        "        assert os.path.isdir(dir), dir\n",
        "        self.full_dir = os.path.join(dir, name)\n",
        "        self.name = name\n",
        "        assert os.path.isdir(self.full_dir), self.full_dir\n",
        "        if shuffle is None:\n",
        "            shuffle = name == 'train'\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # For each category, add up to the self-enforced limit on the number of training/test examples\n",
        "        #\n",
        "        self.imglist = []\n",
        "        for catname in glob('%s/%s/*' % (dir, name)):\n",
        "            catlist = glob('%s/*' % catname)\n",
        "            c = 0\n",
        "            for fname in catlist:\n",
        "                self.imglist.append( (fname, os.path.basename(os.path.dirname(fname))) )\n",
        "                c = c+1\n",
        "                if name == 'train' and c >= 100:\n",
        "                    break\n",
        "                if name == 'test' and c >= 100:\n",
        "                    break\n",
        "\n",
        "        # Compact variant with no limits; just read all the data\n",
        "        # We don't do this for speed reasons\n",
        "        # self.imglist2 = [(fname, os.path.basename(os.path.dirname(fname))) for fname in glob('%s/%s/*/*' % (dir, name))]\n",
        "\n",
        "        self.label_lookup = dict()\n",
        "        for label in sorted(set(i[1] for i in self.imglist)):\n",
        "            self.label_lookup[label] = len(self.label_lookup)\n",
        "\n",
        "        self.imglist = [(fname, self.label_lookup[dirname]) for fname, dirname in self.imglist]\n",
        "\n",
        "        \n",
        "        idxs = np.arange(len(self.imglist))\n",
        "\n",
        "        # Load images into numpy array\n",
        "        self.imgs = np.zeros( (img_size, img_size, 3, len(self.imglist) ), dtype=np.float )\n",
        "        for k in idxs:\n",
        "            fname, label = self.imglist[k]\n",
        "            img = cv2.resize( cv2.imread(fname), (img_size, img_size) )\n",
        "            img = img / 255.0 # You might want to remove this line for your standardization.\n",
        "            self.imgs[:,:,:,k] = img\n",
        "\n",
        "        ########################################################\n",
        "        # TASK 1: Add standardization (also called feature scaling or data normalization).\n",
        "        # Reference here: https://en.wikipedia.org/wiki/Feature_scaling\n",
        "        # To think about: In what different ways could we 'standardize' our data? What would each do?\n",
        "        \n",
        "        mean_img = np.mean(self.imgs, axis = 3)\n",
        "        std_img = np.std(self.imgs, axis = 3)\n",
        "\n",
        "        for k in idxs:\n",
        "            self.imgs[:,:,:,k] = (self.imgs[:,:,:,k] - mean_img) / std_img\n",
        "\n",
        "        ########################################################\n",
        "\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def get_data(self):\n",
        "        idxs = np.arange(len(self.imglist))\n",
        "        if self.shuffle:\n",
        "            self.rng.shuffle(idxs)\n",
        "        for k in idxs:\n",
        "            fname, label = self.imglist[k]\n",
        "            fname = os.path.join(self.full_dir, fname)\n",
        "            yield [self.imgs[:,:,:,k], label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSUGkkN-9ELj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convenience function to load the 15 Scene database.\n",
        "This is where you would place any potential data augmentations.\n",
        "\"\"\"\n",
        "def get_data(datadir, train_or_test):\n",
        "    isTrain = train_or_test == 'train'\n",
        "    img_size = 224 # Hard coded, as VGG-16 network must have this input size\n",
        "\n",
        "    ds = Scene15(datadir, train_or_test, img_size)\n",
        "    if isTrain:\n",
        "        augmentors = [\n",
        "            #################################################\n",
        "            # TASK 1: Add data augmentations\n",
        "            #\n",
        "            # An example (that is duplicated work).\n",
        "            # In the Scene15 class, we resize each image to \n",
        "            # 64x64 pixels as a preprocess. You then perform\n",
        "            # standardization over the images in Task 1.\n",
        "            #\n",
        "            # However, if we wanted to skip standardization, \n",
        "            # we could use an augmentation to resize the image\n",
        "            # whenever it is needed:\n",
        "            # imgaug.Resize( (img_size, img_size) )\n",
        "            #\n",
        "            # Please use the same syntax to write more useful \n",
        "            # augmentations. Read the documentation on the \n",
        "            # TensorPack image augmentation library and experiment!\n",
        "            #################################################\n",
        "            # imgaug.RandomCrop((50, 50)),\n",
        "            # imgaug.Resize((img_size, img_size)),\n",
        "            # imgaug.Shift()\n",
        "        ]\n",
        "    else:\n",
        "        # Validation/test time augmentations\n",
        "        augmentors = [\n",
        "            # imgaug.Resize( (img_size, img_size) ) \n",
        "            # imgaug.RandomCrop((50, 50)),\n",
        "            # imgaug.Resize((img_size, img_size)),\n",
        "            # imgaug.Shift()\n",
        "        ]\n",
        "    # TensorPack: Add data augmentations\n",
        "    ds = AugmentImageComponent(ds, augmentors)\n",
        "    # TensorPack: How to batch the data\n",
        "    # if isTrain:\n",
        "    #     with open('train_data', 'rb') as train_data_file:\n",
        "    #         ds = pickle.load(train_data_file)\n",
        "    # else:\n",
        "    #   with open('test_data', 'rb') as test_data_file:\n",
        "    #         ds = pickle.load(test_data_file)\n",
        "    ds = BatchData(ds, 50, remainder=not isTrain)\n",
        "    if isTrain:\n",
        "        # TensorPack: Perform clever image fetching, e.g., multithreaded\n",
        "        # These numbers will depend on your particular machine.\n",
        "        # Note: PrefetchData seems to be broken on Windows : /\n",
        "        if not sys.platform.lower().startswith('win'):\n",
        "            ds = PrefetchData(ds, 4, 2)\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91I98ii3W0AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_incorrect(logits, label, topk=1, name='incorrect_vector'):\n",
        "  with tf.name_scope('prediction_incorrect'):\n",
        "    # x = tf.logical_not(tf.nn.in_top_k(label, logits, topk))\n",
        "    x = tf.logical_not(tf.nn.in_top_k(logits, label, topk))\n",
        "  return tf.cast(x, tf.float32, name=name)\n",
        "\n",
        "\n",
        "class VGGModel(ModelDesc):\n",
        "  def __init__(self):\n",
        "    super(VGGModel, self).__init__()\n",
        "    self.activation_fn = tf.nn.relu\n",
        "    self.conv_padding = 'SAME'\n",
        "    self.pool_padding = 'SAME'\n",
        "    self.use_bias = True\n",
        "\n",
        "\n",
        "  def inputs(self):\n",
        "    return [tf.TensorSpec([None, 224, 224, 3], tf.float32, 'input'),\n",
        "            tf.TensorSpec([None], tf.int32, 'label')]\n",
        "\n",
        "  def build_graph(self, image, label):\n",
        "    ################################################################################\n",
        "    # TASK 2: Fine tuning\n",
        "    #\n",
        "    # We wish to replace VGG's last fully connected layer. \n",
        "    # We need to change the number of classes for our output, too.\n",
        "    #\n",
        "    # Each layer has a name. TensorPack will load the weights from vgg16.npy and \n",
        "    # match the names of the specified layers to the layers which exist in vgg16.npy.\n",
        "    # In this case, we need to _use a different name than fc8_, otherwise TensorPack\n",
        "    # will copy over the existing weights.\n",
        "    #\n",
        "    # Training will take _a long time_ when not on a GPU - two hours per epoch on \n",
        "    # James' laptop CPU. Run it using Google Cloud Platform!\n",
        "    # There is also a feature to continue from where you left off (per epoch).\n",
        "    # You'll notice it once you've executed run.py multiple times.\n",
        "    #\n",
        "    # Weight freezing: It is also possible to stop gradient propagation beyond the \n",
        "    # newly added fc layer. This will limit the ability of the pre-trained network to \n",
        "    # adjust to the new data, but if the representation is already sufficient then it\n",
        "    # will converge much faster. Please investigate this via tf.stop_gradient()\n",
        "    #\n",
        "    ################################################################################\n",
        "\n",
        "    # with tf.variable_scope('var_scope', reuse=tf.AUTO_REUSE):\n",
        "    with argscope(Conv2D, kernel_shape=3, nl=tf.nn.relu):\n",
        "      logits = (LinearWrap(image)\n",
        "                .Conv2D('conv1_1', 64)\n",
        "                .Conv2D('conv1_2', 64)\n",
        "                .MaxPooling('pool1', 2)\n",
        "                # 112\n",
        "                .Conv2D('conv2_1', 128)\n",
        "                .Conv2D('conv2_2', 128)\n",
        "                .MaxPooling('pool2', 2)\n",
        "                # 56\n",
        "                .Conv2D('conv3_1', 256)\n",
        "                .Conv2D('conv3_2', 256)\n",
        "                .Conv2D('conv3_3', 256)\n",
        "                .MaxPooling('pool3', 2)\n",
        "                # 28\n",
        "                .Conv2D('conv4_1', 512)\n",
        "                .Conv2D('conv4_2', 512)\n",
        "                .Conv2D('conv4_3', 512)\n",
        "                .MaxPooling('pool4', 2)\n",
        "                # 14\n",
        "                .Conv2D('conv5_1', 512)\n",
        "                .Conv2D('conv5_2', 512)\n",
        "                .Conv2D('conv5_3', 512)\n",
        "                .MaxPooling('pool5', 2)\n",
        "                # 7\n",
        "                .FullyConnected('fc6', 4096, nl=tf.nn.relu)\n",
        "                .FullyConnected('fc7', 4096, nl=tf.nn.relu)\n",
        "                # .FullyConnected('fc8', out_dim=1000, nl=tf.identity)()\n",
        "\n",
        "                .FullyConnected('fc11', 4096, nl=tf.nn.relu)\n",
        "                .FullyConnected('fc12', out_dim=15, nl=tf.identity)()\n",
        "                )\n",
        "          \n",
        "    prob = tf.nn.softmax(logits, name='output')\n",
        "\n",
        "    cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n",
        "    cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n",
        "\n",
        "    wrong = prediction_incorrect(logits, label)\n",
        "\n",
        "    # monitor training error\n",
        "    add_moving_summary(tf.reduce_mean(wrong, name='train_error'))\n",
        "\n",
        "    add_moving_summary(cost)\n",
        "\n",
        "    add_param_summary(('.*/W', ['histogram']))   # monitor W\n",
        "    self.cost = tf.add_n([cost], name='cost')\n",
        "    return self.cost\n",
        "\n",
        "  def optimizer(self):\n",
        "        # opt = tf.compat.v1.train.RMSPropOptimizer(hp.learning_rate)\n",
        "        opt = tf.train.RMSPropOptimizer(0.01)\n",
        "        return opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMQE9yH-9H4t",
        "colab_type": "code",
        "outputId": "bebe491e-0345-44ca-eaee-96cf828b11db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument(\n",
        "#     '--task',\n",
        "#     required=True,\n",
        "#     choices=['1', '2'],\n",
        "#     help='Which task of the assignment to run - training from scratch (1), or fine tuning VGG-16 (2).')\n",
        "# # Set GPU to -1 to not use a GPU.\n",
        "# parser.add_argument('--gpu', help='Comma-separated list of GPU(s) to use.')\n",
        "# parser.add_argument(\n",
        "#     '--load',\n",
        "#     # Location of pre-trained model\n",
        "#     # - As a relative path to the student distribution\n",
        "#     default='../vgg16.npy',\n",
        "#     # - As an absolute path to the location on the Brown CS filesystem\n",
        "#     #default='/course/cs1430/pretrained_weights/vgg16.npy',\n",
        "#     help='Load VGG-16 model.')\n",
        "load = '/content/drive/My Drive/vgg16.npy'\n",
        "# parser.add_argument(\n",
        "#     '--data',\n",
        "#     # Location of 15 Scenes dataset\n",
        "#     # - As a relative path to the student distribution\n",
        "#     default=os.getcwd() + '/../data/',\n",
        "#     # - As an absolute path to the location on the Brown CS filesystem\n",
        "#     #default='/course/cs1430/datasets/15SceneData/',\n",
        "#     help='Location where the dataset is stored.')\n",
        "data = '/content/drive/My Drive/data/'\n",
        "\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# if args.gpu:\n",
        "#     os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "\n",
        "# logger.auto_set_dir()\n",
        "logger.set_logger_dir('/content/drive/My Drive/tensorpack_log')\n",
        "\n",
        "dataset_train = get_data(data, 'train')\n",
        "dataset_test = get_data(data, 'test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:30:55 @logger.py:126]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory /content/drive/My Drive/tensorpack_log exists! Use 'd' to delete it. \n",
            "\u001b[32m[1112 17:30:55 @logger.py:129]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n",
            "Press any other key to exit. \n",
            "Select Action: k (keep) / d (delete) / q (quit):k\n",
            "\u001b[32m[1112 17:30:58 @logger.py:90]\u001b[0m Argv: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-0aa7bfb5-418b-4f98-a12e-561ed97477bd.json\n",
            "\u001b[32m[1112 17:40:09 @parallel.py:231]\u001b[0m [MultiProcessRunner] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n",
            "\u001b[32m[1112 17:40:09 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is not safe and may consume unnecessary extra CPU memory. Use 'forkserver/spawn' method (available after Py3.4) instead if you run into any issues. See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
            "\u001b[32m[1112 17:40:09 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UqBC3WFcEM",
        "colab_type": "code",
        "outputId": "2ee69250-831b-4dba-bec4-8dc371e0b679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "logger.set_logger_dir('/content/drive/My Drive/tensorpack_log')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 16:31:53 @logger.py:126]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory /content/drive/My Drive/tensorpack_log exists! Use 'd' to delete it. \n",
            "\u001b[32m[1112 16:31:53 @logger.py:129]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n",
            "Press any other key to exit. \n",
            "Select Action: k (keep) / d (delete) / q (quit):d\n",
            "\u001b[32m[1112 16:31:55 @logger.py:90]\u001b[0m Argv: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-bece6984-1673-4679-9ae7-02c07c5c2fb0.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DqmXTm2QOcH",
        "colab_type": "code",
        "outputId": "170afcb6-8d82-491a-f8eb-0a8cd2e0af58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TensorPack: Training configuration\n",
        "config = TrainConfig(\n",
        "    model=VGGModel(),\n",
        "    dataflow=dataset_train,\n",
        "    callbacks=[\n",
        "        # Callbacks are performed at the end of every epoch.\n",
        "        #\n",
        "        # For instance, we can save the current model\n",
        "        ModelSaver(),\n",
        "        # Evaluate the current model and print out the loss\n",
        "        InferenceRunner(dataset_test,\n",
        "                        [ScalarStats('cost'), ClassificationError()])\n",
        "        #\n",
        "        # You can put other callbacks here to change hyperparameters,\n",
        "        # etc...\n",
        "        #\n",
        "    ],\n",
        "    max_epoch=30,\n",
        "    nr_tower=max(get_nr_gpu(), 1),\n",
        "    session_init=get_model_loader(load)\n",
        ")\n",
        "launch_train_with_config(config, SimpleTrainer())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:49:58 @sessinit.py:294]\u001b[0m Loading dictionary from /content/drive/My Drive/vgg16.npy ...\n",
            "\u001b[32m[1112 17:50:03 @trainers.py:47]\u001b[0m Building graph for a single training tower ...\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv1_1': [?, 224, 224, 3] --> [?, 224, 224, 64]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv1_2': [?, 224, 224, 64] --> [?, 224, 224, 64]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'pool1': [?, 224, 224, 64] --> [?, 112, 112, 64]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv2_1': [?, 112, 112, 64] --> [?, 112, 112, 128]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv2_2': [?, 112, 112, 128] --> [?, 112, 112, 128]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'pool2': [?, 112, 112, 128] --> [?, 56, 56, 128]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv3_1': [?, 56, 56, 128] --> [?, 56, 56, 256]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv3_2': [?, 56, 56, 256] --> [?, 56, 56, 256]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv3_3': [?, 56, 56, 256] --> [?, 56, 56, 256]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'pool3': [?, 56, 56, 256] --> [?, 28, 28, 256]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv4_1': [?, 28, 28, 256] --> [?, 28, 28, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv4_2': [?, 28, 28, 512] --> [?, 28, 28, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv4_3': [?, 28, 28, 512] --> [?, 28, 28, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'pool4': [?, 28, 28, 512] --> [?, 14, 14, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv5_1': [?, 14, 14, 512] --> [?, 14, 14, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv5_2': [?, 14, 14, 512] --> [?, 14, 14, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'conv5_3': [?, 14, 14, 512] --> [?, 14, 14, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'pool5': [?, 14, 14, 512] --> [?, 7, 7, 512]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'fc6': [?, 7, 7, 512] --> [?, 4096]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'fc7': [?, 4096] --> [?, 4096]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'fc11': [?, 4096] --> [?, 4096]\n",
            "\u001b[32m[1112 17:50:04 @registry.py:90]\u001b[0m 'fc12': [?, 4096] --> [?, 15]\n",
            "\u001b[32m[1112 17:50:05 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n",
            "\u001b[0mname       shape               #elements\n",
            "---------  ----------------  -----------\n",
            "conv1_1/W  [3, 3, 3, 64]            1728\n",
            "conv1_1/b  [64]                       64\n",
            "conv1_2/W  [3, 3, 64, 64]          36864\n",
            "conv1_2/b  [64]                       64\n",
            "conv2_1/W  [3, 3, 64, 128]         73728\n",
            "conv2_1/b  [128]                     128\n",
            "conv2_2/W  [3, 3, 128, 128]       147456\n",
            "conv2_2/b  [128]                     128\n",
            "conv3_1/W  [3, 3, 128, 256]       294912\n",
            "conv3_1/b  [256]                     256\n",
            "conv3_2/W  [3, 3, 256, 256]       589824\n",
            "conv3_2/b  [256]                     256\n",
            "conv3_3/W  [3, 3, 256, 256]       589824\n",
            "conv3_3/b  [256]                     256\n",
            "conv4_1/W  [3, 3, 256, 512]      1179648\n",
            "conv4_1/b  [512]                     512\n",
            "conv4_2/W  [3, 3, 512, 512]      2359296\n",
            "conv4_2/b  [512]                     512\n",
            "conv4_3/W  [3, 3, 512, 512]      2359296\n",
            "conv4_3/b  [512]                     512\n",
            "conv5_1/W  [3, 3, 512, 512]      2359296\n",
            "conv5_1/b  [512]                     512\n",
            "conv5_2/W  [3, 3, 512, 512]      2359296\n",
            "conv5_2/b  [512]                     512\n",
            "conv5_3/W  [3, 3, 512, 512]      2359296\n",
            "conv5_3/b  [512]                     512\n",
            "fc6/W      [25088, 4096]       102760448\n",
            "fc6/b      [4096]                   4096\n",
            "fc7/W      [4096, 4096]         16777216\n",
            "fc7/b      [4096]                   4096\n",
            "fc11/W     [4096, 4096]         16777216\n",
            "fc11/b     [4096]                   4096\n",
            "fc12/W     [4096, 15]              61440\n",
            "fc12/b     [15]                       15\u001b[36m\n",
            "Number of trainable variables: 34\n",
            "Number of parameters (elements): 151103311\n",
            "Storage space needed for all trainable variables: 576.41MB\u001b[0m\n",
            "\u001b[32m[1112 17:50:05 @base.py:209]\u001b[0m Setup callbacks graph ...\n",
            "\u001b[32m[1112 17:50:05 @inference_runner.py:149]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n",
            "\u001b[32m[1112 17:50:05 @summary.py:47]\u001b[0m [MovingAverageSummary] 2 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n",
            "\u001b[32m[1112 17:50:05 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 19.\n",
            "\u001b[32m[1112 17:50:05 @base.py:230]\u001b[0m Creating the session ...\n",
            "\u001b[32m[1112 17:50:14 @base.py:236]\u001b[0m Initializing the session ...\n",
            "\u001b[32m[1112 17:50:14 @sessinit.py:223]\u001b[0m Variables to restore from dict: conv1_1/W, conv1_1/b, conv1_2/W, conv1_2/b, conv2_1/W, conv2_1/b, conv2_2/W, conv2_2/b, conv3_1/W, conv3_1/b, conv3_2/W, conv3_2/b, conv3_3/W, conv3_3/b, conv4_1/W, conv4_1/b, conv4_2/W, conv4_2/b, conv4_3/W, conv4_3/b, conv5_1/W, conv5_1/b, conv5_2/W, conv5_2/b, conv5_3/W, conv5_3/b, fc6/W, fc6/b, fc7/W, fc7/b\n",
            "\u001b[32m[1112 17:50:14 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the dict: fc11/W, fc11/b, fc12/W, fc12/b, global_step\n",
            "\u001b[32m[1112 17:50:14 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the dict, but not found in the graph: fc8/W, fc8/b\n",
            "\u001b[32m[1112 17:50:14 @sessinit.py:236]\u001b[0m Restoring 30 variables from dict ...\n",
            "\u001b[32m[1112 17:50:14 @varmanip.py:88]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The tensor is reshaped from (7, 7, 512, 4096) to (25088, 4096) when assigned to 'fc6/W'\n",
            "\u001b[32m[1112 17:50:15 @base.py:243]\u001b[0m Graph Finalized.\n",
            "\u001b[32m[1112 17:50:15 @inference_runner.py:96]\u001b[0m [InferenceRunner] Will eval 30 iterations\n",
            "\u001b[32m[1112 17:50:15 @monitor.py:359]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=2 from JSON is not the predecessor of the current starting_epoch=1\n",
            "\u001b[32m[1112 17:50:15 @monitor.py:360]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n",
            "\u001b[32m[1112 17:50:15 @monitor.py:367]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to /content/drive/My Drive/tensorpack_log/stats.json.1112-175015\n",
            "\u001b[32m[1112 17:50:15 @base.py:275]\u001b[0m Start Epoch 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:25<00:00, 1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:50:41 @base.py:285]\u001b[0m Epoch 1 (global_step 30) finished, time:25.8 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:50:50 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-30.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:50:59 @monitor.py:474]\u001b[0m cross_entropy_loss: 2.9852\n",
            "\u001b[32m[1112 17:50:59 @monitor.py:474]\u001b[0m train_error: 0.87908\n",
            "\u001b[32m[1112 17:50:59 @monitor.py:474]\u001b[0m validation_cost: 2.2335\n",
            "\u001b[32m[1112 17:50:59 @monitor.py:474]\u001b[0m validation_error: 0.762\n",
            "\u001b[32m[1112 17:50:59 @group.py:48]\u001b[0m Callbacks took 18.469 sec in total. ModelSaver: 8.76 seconds; InferenceRunner: 9.7 seconds\n",
            "\u001b[32m[1112 17:50:59 @base.py:275]\u001b[0m Start Epoch 2 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:51:16 @base.py:285]\u001b[0m Epoch 2 (global_step 60) finished, time:16.8 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:51:23 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-60.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:51:33 @monitor.py:474]\u001b[0m cross_entropy_loss: 5.4376e+13\n",
            "\u001b[32m[1112 17:51:33 @monitor.py:474]\u001b[0m train_error: 0.92457\n",
            "\u001b[32m[1112 17:51:33 @monitor.py:474]\u001b[0m validation_cost: 1.579e+08\n",
            "\u001b[32m[1112 17:51:33 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:51:33 @group.py:48]\u001b[0m Callbacks took 16.696 sec in total. ModelSaver: 6.89 seconds; InferenceRunner: 9.79 seconds\n",
            "\u001b[32m[1112 17:51:33 @base.py:275]\u001b[0m Start Epoch 3 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:51:50 @base.py:285]\u001b[0m Epoch 3 (global_step 90) finished, time:16.9 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:51:57 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-90.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:52:07 @monitor.py:474]\u001b[0m cross_entropy_loss: 1.1245e+13\n",
            "\u001b[32m[1112 17:52:07 @monitor.py:474]\u001b[0m train_error: 0.92647\n",
            "\u001b[32m[1112 17:52:07 @monitor.py:474]\u001b[0m validation_cost: 1.5933e+06\n",
            "\u001b[32m[1112 17:52:07 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:52:07 @group.py:48]\u001b[0m Callbacks took 17.151 sec in total. ModelSaver: 7.65 seconds; InferenceRunner: 9.48 seconds\n",
            "\u001b[32m[1112 17:52:07 @base.py:275]\u001b[0m Start Epoch 4 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:52:24 @base.py:285]\u001b[0m Epoch 4 (global_step 120) finished, time:16.7 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:52:31 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-120.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:52:40 @monitor.py:474]\u001b[0m cross_entropy_loss: 2.3948e+12\n",
            "\u001b[32m[1112 17:52:40 @monitor.py:474]\u001b[0m train_error: 0.93917\n",
            "\u001b[32m[1112 17:52:40 @monitor.py:474]\u001b[0m validation_cost: 4697.7\n",
            "\u001b[32m[1112 17:52:40 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:52:40 @group.py:48]\u001b[0m Callbacks took 16.256 sec in total. ModelSaver: 6.86 seconds; InferenceRunner: 9.37 seconds\n",
            "\u001b[32m[1112 17:52:40 @base.py:275]\u001b[0m Start Epoch 5 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:52:57 @base.py:285]\u001b[0m Epoch 5 (global_step 150) finished, time:16.7 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:53:03 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-150.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:53:13 @monitor.py:474]\u001b[0m cross_entropy_loss: 5.1316e+11\n",
            "\u001b[32m[1112 17:53:13 @monitor.py:474]\u001b[0m train_error: 0.92524\n",
            "\u001b[32m[1112 17:53:13 @monitor.py:474]\u001b[0m validation_cost: 198.88\n",
            "\u001b[32m[1112 17:53:13 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:53:13 @group.py:48]\u001b[0m Callbacks took 16.135 sec in total. ModelSaver: 6.72 seconds; InferenceRunner: 9.39 seconds\n",
            "\u001b[32m[1112 17:53:13 @base.py:275]\u001b[0m Start Epoch 6 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:53:29 @base.py:285]\u001b[0m Epoch 6 (global_step 180) finished, time:16.5 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:53:36 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-180.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:53:46 @monitor.py:474]\u001b[0m cross_entropy_loss: 1.101e+11\n",
            "\u001b[32m[1112 17:53:46 @monitor.py:474]\u001b[0m train_error: 0.93084\n",
            "\u001b[32m[1112 17:53:46 @monitor.py:474]\u001b[0m validation_cost: 5.5354\n",
            "\u001b[32m[1112 17:53:46 @monitor.py:474]\u001b[0m validation_error: 0.932\n",
            "\u001b[32m[1112 17:53:46 @group.py:48]\u001b[0m Callbacks took 16.342 sec in total. ModelSaver: 6.95 seconds; InferenceRunner: 9.37 seconds\n",
            "\u001b[32m[1112 17:53:46 @base.py:275]\u001b[0m Start Epoch 7 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:54:02 @base.py:285]\u001b[0m Epoch 7 (global_step 210) finished, time:16.5 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:54:08 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-210.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:54:18 @monitor.py:474]\u001b[0m cross_entropy_loss: 2.3671e+10\n",
            "\u001b[32m[1112 17:54:18 @monitor.py:474]\u001b[0m train_error: 0.93386\n",
            "\u001b[32m[1112 17:54:18 @monitor.py:474]\u001b[0m validation_cost: 1.0361e+07\n",
            "\u001b[32m[1112 17:54:18 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:54:18 @group.py:48]\u001b[0m Callbacks took 15.523 sec in total. ModelSaver: 6.17 seconds; InferenceRunner: 9.34 seconds\n",
            "\u001b[32m[1112 17:54:18 @base.py:275]\u001b[0m Start Epoch 8 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:54:34 @base.py:285]\u001b[0m Epoch 8 (global_step 240) finished, time:16.6 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:54:42 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-240.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:54:51 @monitor.py:474]\u001b[0m cross_entropy_loss: 5.0819e+09\n",
            "\u001b[32m[1112 17:54:51 @monitor.py:474]\u001b[0m train_error: 0.93078\n",
            "\u001b[32m[1112 17:54:51 @monitor.py:474]\u001b[0m validation_cost: 20376\n",
            "\u001b[32m[1112 17:54:51 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:54:51 @group.py:48]\u001b[0m Callbacks took 16.938 sec in total. ModelSaver: 7.6 seconds; InferenceRunner: 9.32 seconds\n",
            "\u001b[32m[1112 17:54:51 @base.py:275]\u001b[0m Start Epoch 9 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:55:08 @base.py:285]\u001b[0m Epoch 9 (global_step 270) finished, time:16.5 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:55:14 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-270.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:55:23 @monitor.py:474]\u001b[0m cross_entropy_loss: 1.0909e+09\n",
            "\u001b[32m[1112 17:55:23 @monitor.py:474]\u001b[0m train_error: 0.92599\n",
            "\u001b[32m[1112 17:55:23 @monitor.py:474]\u001b[0m validation_cost: 4.6432e+05\n",
            "\u001b[32m[1112 17:55:23 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:55:23 @group.py:48]\u001b[0m Callbacks took 15.748 sec in total. ModelSaver: 6.35 seconds; InferenceRunner: 9.37 seconds\n",
            "\u001b[32m[1112 17:55:23 @base.py:275]\u001b[0m Start Epoch 10 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:55:40 @base.py:285]\u001b[0m Epoch 10 (global_step 300) finished, time:16.7 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:55:47 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-300.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:55:56 @monitor.py:474]\u001b[0m cross_entropy_loss: 2.3416e+08\n",
            "\u001b[32m[1112 17:55:56 @monitor.py:474]\u001b[0m train_error: 0.9281\n",
            "\u001b[32m[1112 17:55:56 @monitor.py:474]\u001b[0m validation_cost: 104.28\n",
            "\u001b[32m[1112 17:55:56 @monitor.py:474]\u001b[0m validation_error: 0.918\n",
            "\u001b[32m[1112 17:55:56 @group.py:48]\u001b[0m Callbacks took 16.105 sec in total. ModelSaver: 6.75 seconds; InferenceRunner: 9.34 seconds\n",
            "\u001b[32m[1112 17:55:56 @base.py:275]\u001b[0m Start Epoch 11 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:56:13 @base.py:285]\u001b[0m Epoch 11 (global_step 330) finished, time:16.6 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:56:21 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-330.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:56:31 @monitor.py:474]\u001b[0m cross_entropy_loss: 5.0261e+07\n",
            "\u001b[32m[1112 17:56:31 @monitor.py:474]\u001b[0m train_error: 0.92863\n",
            "\u001b[32m[1112 17:56:31 @monitor.py:474]\u001b[0m validation_cost: 72.25\n",
            "\u001b[32m[1112 17:56:31 @monitor.py:474]\u001b[0m validation_error: 0.91667\n",
            "\u001b[32m[1112 17:56:31 @group.py:48]\u001b[0m Callbacks took 17.776 sec in total. ModelSaver: 8.35 seconds; InferenceRunner: 9.41 seconds\n",
            "\u001b[32m[1112 17:56:31 @base.py:275]\u001b[0m Start Epoch 12 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:56:47 @base.py:285]\u001b[0m Epoch 12 (global_step 360) finished, time:16.5 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:56:54 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-360.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:57:03 @monitor.py:474]\u001b[0m cross_entropy_loss: 1.0788e+07\n",
            "\u001b[32m[1112 17:57:03 @monitor.py:474]\u001b[0m train_error: 0.92453\n",
            "\u001b[32m[1112 17:57:03 @monitor.py:474]\u001b[0m validation_cost: 3.0399\n",
            "\u001b[32m[1112 17:57:03 @monitor.py:474]\u001b[0m validation_error: 0.92267\n",
            "\u001b[32m[1112 17:57:03 @group.py:48]\u001b[0m Callbacks took 15.943 sec in total. ModelSaver: 6.57 seconds; InferenceRunner: 9.35 seconds\n",
            "\u001b[32m[1112 17:57:03 @base.py:275]\u001b[0m Start Epoch 13 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:57:20 @base.py:285]\u001b[0m Epoch 13 (global_step 390) finished, time:16.4 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:57:26 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-390.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:57:36 @monitor.py:474]\u001b[0m cross_entropy_loss: 2.3155e+06\n",
            "\u001b[32m[1112 17:57:36 @monitor.py:474]\u001b[0m train_error: 0.92678\n",
            "\u001b[32m[1112 17:57:36 @monitor.py:474]\u001b[0m validation_cost: 2.7919\n",
            "\u001b[32m[1112 17:57:36 @monitor.py:474]\u001b[0m validation_error: 0.89733\n",
            "\u001b[32m[1112 17:57:36 @group.py:48]\u001b[0m Callbacks took 16.286 sec in total. ModelSaver: 6.87 seconds; InferenceRunner: 9.39 seconds\n",
            "\u001b[32m[1112 17:57:36 @base.py:275]\u001b[0m Start Epoch 14 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:57:53 @base.py:285]\u001b[0m Epoch 14 (global_step 420) finished, time:16.8 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:57:59 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-420.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:58:09 @monitor.py:474]\u001b[0m cross_entropy_loss: 1.1269e+08\n",
            "\u001b[32m[1112 17:58:09 @monitor.py:474]\u001b[0m train_error: 0.93506\n",
            "\u001b[32m[1112 17:58:09 @monitor.py:474]\u001b[0m validation_cost: 8092.8\n",
            "\u001b[32m[1112 17:58:09 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:58:09 @group.py:48]\u001b[0m Callbacks took 16.272 sec in total. ModelSaver: 6.87 seconds; InferenceRunner: 9.38 seconds\n",
            "\u001b[32m[1112 17:58:09 @base.py:275]\u001b[0m Start Epoch 15 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:58:25 @base.py:285]\u001b[0m Epoch 15 (global_step 450) finished, time:16.5 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:58:32 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-450.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:58:42 @monitor.py:474]\u001b[0m cross_entropy_loss: 2.4211e+07\n",
            "\u001b[32m[1112 17:58:42 @monitor.py:474]\u001b[0m train_error: 0.92931\n",
            "\u001b[32m[1112 17:58:42 @monitor.py:474]\u001b[0m validation_cost: 11927\n",
            "\u001b[32m[1112 17:58:42 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:58:42 @group.py:48]\u001b[0m Callbacks took 16.196 sec in total. ModelSaver: 6.72 seconds; InferenceRunner: 9.44 seconds\n",
            "\u001b[32m[1112 17:58:42 @base.py:275]\u001b[0m Start Epoch 16 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########|30/30[00:16<00:00, 1.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:58:58 @base.py:285]\u001b[0m Epoch 16 (global_step 480) finished, time:16.5 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:59:05 @saver.py:82]\u001b[0m Model saved to /content/drive/My Drive/tensorpack_log/model-480.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########|30/30[00:09<00:00, 3.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[1112 17:59:14 @monitor.py:474]\u001b[0m cross_entropy_loss: 5.197e+06\n",
            "\u001b[32m[1112 17:59:14 @monitor.py:474]\u001b[0m train_error: 0.92903\n",
            "\u001b[32m[1112 17:59:14 @monitor.py:474]\u001b[0m validation_cost: 2.9458\n",
            "\u001b[32m[1112 17:59:14 @monitor.py:474]\u001b[0m validation_error: 0.93333\n",
            "\u001b[32m[1112 17:59:14 @group.py:48]\u001b[0m Callbacks took 16.141 sec in total. ModelSaver: 6.7 seconds; InferenceRunner: 9.43 seconds\n",
            "\u001b[32m[1112 17:59:14 @base.py:275]\u001b[0m Start Epoch 17 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|##        |6/30[00:02<00:08, 2.76it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLgl2Ccgabbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}